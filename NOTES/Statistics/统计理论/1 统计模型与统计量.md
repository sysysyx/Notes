# 正态分布的抽样

## 三大分布

统计推断的核心内容: 抽样分布, 参数估计, 假设检验. 本章主要研究正态整体下各种统计量的分布:
$$X\sim N(a,\sigma^2),\quad \begin{cases}
f(x)= \frac{1}{2\pi \sigma}\exp\left\{ - \frac{(x-a)^2}{2\sigma^2} \right\} \\
\varphi_{k}(t)=\mathbb E(\exp(itX_{k}))=e^{iat- \frac{1}{2}\sigma^2t^2}
\end{cases}$$
由此容易推出正态分布样本均值的分布
$$\text{i.i.d.}X_{i}\sim N(a,\sigma^2)\implies \bar{X}\sim N(a, \sigma^2 / n)$$
方差的分布没有简单的表示, 但是可以推断

> [!proposition]
> 独立正态分布样本的均值和方差相互独立

`BEGINPROOF`



考虑正交阵 (其存在性由 Schmidt 正交化保证)
$$A=\begin{pmatrix}
\frac{1}{\sqrt{ n }}&\frac{1}{\sqrt{ n }}&\cdots&\frac{1}{\sqrt{ n }} \\
a_{21}&a_{22}&\cdots& a_{2n} \\
\vdots&\vdots&&\vdots \\
a_{n1}&a_{n 2}&\cdots&a_{nn}
\end{pmatrix}$$

记其 $Y=AX$ , 则由于 $X_{i}$ 为独立同分布的正态分布随机变量, $Y_i$ 也是正太分布, 并且
$$\mathbb E(Y_{i})=a\sum_{k=1}^na_{ik},\qquad var(Y_{i})=\sigma^2\sum a_{ik}^2=\sigma^2$$
并且由于正交性
$$\begin{align}
cov(Y_{i},Y_{j})&=\mathbb E[(Y_{i}-\mathbb EY_{i})(Y_{j}-\mathbb EY_{j})] \\
&=\sum_{k=1}^n\sum_{l=1}^na_{ik}a_{jl}\mathbb E[(X_{k}-a)(X_{l}-a)] \\
&=\sigma^2\sum_{k=1}^na_{ik}a_{jk}=0
\end{align}$$
从而 $Y_{i}$ 相互独立 (这里必须要正态分布才能推出), 再由
$$Y_{1}=\sqrt{ n }\bar{X}$$
而正交向量保持长度不变, 从而
$$\sum Y_{i}^2=\sum X_{n}^2\implies(n-1)S^2=\sum(X_{i}-\bar{X})^2=\sum X_{i}^2-n\bar{X}^2=\sum Y_{i}^2-Y_{1}^2=\sum_{i=2}^nY_{i}^2$$
这就是说 $\bar{X}$ 只与 $Y_{1}$ 有关, 而 $S^2$ 只与 $Y_{2}\cdots Y_{n}$ 有关.
`ENDPROOF`

为了表示方差的分布, 定义

> [!def] $\chi^2$ 分布
> 设 $\text{i.i.d. }X_{i}\sim N(0,1)$, 则称 $\xi=\sum_{i=1}^nX_{i}^2\sim \chi_{n}^2$, 其概率密度函数和特征函数形如
> $$g_{n}(x)=\begin{cases}
> \frac{x^{n/2-1}e^{-x/2}}{2^{n/2}\Gamma( n / 2)}&x>0 \\
> 0&x\leq0
> \end{cases}
> \qquad
> \varphi_{n}(t)=(1-2it)^{- n / 2 }
> $$
> 均值和方差为
> $$\mathbb E(\xi)=n,\qquad var(\xi)=2n $$

从而对独立正态分布样本的方差 $S_{n}=\sum_{i=1}^n(X_{i}-\bar{X}) / (n-1)$ 有
$$\frac{(n-1)S_{n}^2}{\sigma^2}\sim \chi_{n-1}^2$$

这里需要特殊关注系数 $n-1$, 这是因为 $\bar{X}$ 也是变量, 实际上的自由度只有 $n-1$

为了给出其它一些统计量的分布和性质, 再定义两种常用分布: $t$ 分布和 $F$ 分布

> [!def] $t$ 分布
> 设 $X\sim N(0,1),Y\sim \chi_{n}^2$ 且二者独立, 则称
> $$T= \frac{X}{\sqrt{ Y/n }}\sim t_{n}$$
> 其概率密度函数
> $$t_{n}(x)= \frac{\Gamma\left(  \frac{n+1}{2} \right)}{\Gamma\left(  \frac{n}{2} \right)\sqrt{ n\pi }}\left( 1+ \frac{x^2}{n}  \right)^{-(n+1)/2}$$

从而对上述例子
$$T= \frac{\sqrt{ n }(\bar{X}-a)}{S}\sim t_{n-1}$$

> [!def] $F$ 分布
> $X\sim \chi_{m}^2$, $Y\sim \chi_{n}^2$, 且 $X$, $Y$ 独立, 则称 $F= \frac{X / m}{Y / n}\sim F_{m,n}$, 其密度函数为
> $$f_{m,n}=\begin{cases}
> \frac{\Gamma\left(  \frac{m+n}{2} \right)}{\Gamma\left(  \frac{n}{2} \right)\Gamma\left(  \frac{m}{2} \right)}m^{m/2}n^{n/2}x^{m/2-1}(n+mx)^{-\frac{m+n}{2}}&x>0 \\
> 0&x\leq0
> \end{cases}$$

Properties:
(a) $$\begin{align}
\mathbb E(F)&= \frac{n}{n-2},\quad n>2 \\
\mathbb E(F^r)&=\left(  \frac{n}{m} \right)^r\frac{\Gamma\left(  \frac{n}{2}-r \right)\Gamma\left( \frac{m}{2}+r \right)}{\Gamma\left(  \frac{n}{2} \right)\Gamma\left( \frac{m}{2} \right)}
\end{align}$$
(b) 若记 $F(\alpha)=x:\mathbb P(F>x)=\alpha$ 则
$$F_{m,n}(1-\alpha)=1/F_{n,m}(\alpha)$$

## 次序统计量


# 统计模型简介


# 指数族

指数族是一类较好处理的统计模型, 如正态分布, 二项分布, Poisson 分布, 负二项分布, 指数分布, Gamma 分布. 本节介绍其定义和简单性质

> [!def] 指数族
> 设 $\mathcal F=\{f(x,\theta):\theta\in \Theta\}$ 定义在样本空间 $\mathcal X$ 上的分布族, 若其概率函数可表示为
> $$f(x,\theta)=C(\theta)\exp\left\{ Q^T(\theta)T(x) \right\}h(x),\quad C(\theta)>0,h(x)>0 $$
> 则称其为 $k$ 指数族, 并且若指数族能表示成
> $$f(x,\theta)=C^*(\theta)\exp\left\{ \theta^TT(x) \right\}h(x)$$
> 则称其为为指数族的自然形式, 此时集合
> $$\mathbb R^k\supset \Theta^*=\left\{ (\theta_{1},\cdots,\theta_{k}):\int_{\mathcal X}\exp\left\{ \theta^TT(x) \right\}h(x)\ \mathrm{d}x<\infty \right\}$$
> 称为自然参数空间

可以发现, $C^*(\theta)$ 是完全由 $T$, $h$ 决定的, 称为正交化常量

> [!thm]
> 自然参数空间为凸集

观察形式直接可得

> [!thm]
> 设自然参数空间有非空内点集 $\Theta_{0}$, 对任一实函数 $g(x)$ 使得积分
> $$G(\theta)=\int_{\mathcal X}g(x)\exp\left\{ \theta^TT(x) \right\}h(x)\ \mathrm{d}x$$
> 在 $\Theta_{0}$ 存在且有限, 则 $G$ 的任一阶偏导数在 $\Theta_{0}$ 内存在且可在积分号下求得

另一个有意思的事情是 $M_{\theta}^{T(X)}(u)= \frac{C(\theta)}{C(\theta+u)}$ 为 $T(X)$ 的矩生成函数:
$$\begin{align}
M_{\theta}^{T(X)}(u)&=\mathbb E[e^{u^TT(X)}] \\
&=\int e^{u^TT}e^{\theta^TT}C(\theta)h\ \mathrm{d}\mu \\
&= \frac{C(\theta)}{C(\theta+u)}\underbrace{\int e^{(\theta+u)^TT}C(\theta+u)h\ \mathrm{d}\mu }_{1}
\end{align}$$

这表明
$$\partial^IM_{\theta}^{T(X)}(0)=\mathbb E_{\theta}(T^I)$$
其中 $I$ 为多重指标
# 各种常用统计量

## 充分统计量

> [!def] 充分统计量
> 对于样本分布族 $\{f(\theta,x),\theta\in\Theta\}$, 令 $T=T(X)$ 为一统计量, 若在已知 $T$ 的条件下, 样本 $X$ 的条件分布与参数 $\theta$ 无关, 则称 $T(X)$ 为 $\theta$ 的充分统计量, 实际操作时也会用条件概率(离散情形) 或条件密度 (连续情形) 来代替.

这就是说充分统计量是确定参数 $\theta$ 的充分条件, 其判断方式也很直观

> [!thm] 因子分解定理
> 设样本 $X=(X_{1},\cdots,X_{n})$ 的概率函数 $f(\overrightarrow x,\theta)$ 依赖于参数 $\theta$, $T=T(X)$ 为一统计量, 则 $T=TX$ 为充分统计量的充要条件是 $f(x,\theta)$ 可以分解为
> $$f(x,\theta)=g(t(x),\theta)h(x)$$

给出一个便于理解但不严谨的瞎掰证明

`BEGINPROOF`
必要性显然, 考虑充分性, 令
$$\begin{align}
g_{\theta}(x):&=\mathbb P_{\theta}(T(X)=t)=\int_{T(x)=t}p_{\theta}(x)\ \mathrm{d}\mu \\
h(x):&=\mathbb P(X\mid T)= \frac{p_{\theta_{0}}(x)}{\int_{T(x)=T(x)}p_{\theta_{0}}(z)\ \mathrm{d}\mu (x)}&(\theta\ 无关)
\end{align}$$
从而
$$g_{\theta}(T(x))h(x)=\mathbb P(T(X)=T(x))\mathbb P_{\theta}(X=x\mid T(X)=T(x))=p_{\theta}(x)$$
`ENDPROOF`

下面是充分性的一个应用

> [!thm] Rao Blackwell
> 对于充分统计量 $T(X)$ 和 $g(\theta)$ 的估计 $\delta(X)$, 取 $\bar{\delta}(T(X))=\mathbb E[\delta(X)\mid T(X)]$, 若 $L(\theta;d)$ 是凸的, 则
> $$R(\theta;\bar{\delta})\leq R(\theta;\delta)\quad \forall\delta$$
> 并且若 $L$ 严格凸, 上式严格小于, 处分 $\delta\xlongequal{\text{a.s.}}\bar{\delta}$

^596d0c

`BEGINPROOF`
$$R(\theta;\bar{\delta})=\mathbb E_{\theta}[L(\theta;\mathbb E(\delta\mid T))]\leq\mathbb E_{\theta}[\mathbb E[L(\theta;\delta)\mid T]]=\mathbb E_{\theta}[L(\theta;\delta)]=R(\theta;\delta)$$
这个小于等于号就是 Jenson 不等式 $f凸\implies\mathbb E[f(X)]\geq f[\mathbb E[X]]$
`ENDPROOF`

在这个证明中, $\bar{\delta}$ 能成为统计量的一个必要条件就是 $T$ 为一充分统计量, 对一个估计做上述优化的操作称为 Rao-Blackwellization

## 极小充分统计量

对于分布族 $N(\theta,1)$, 我们至少能找到以下四个充分统计量
$$\begin{matrix}
X=(X_{1},\cdots,X_{n})& S(X)=(X_{(1)},\cdots,X_{(2)})) \\
\sum_{i}X_{i}&\bar{X}= \frac{1}{n}\sum_{i}X_{i}
\end{matrix}$$
甚至不讲道理的说, $X$ 本身是任何分布族的充分统计量, 但这显然不是我们想要的. 假如我们视充分统计量为某种无损的信息压缩, 那我们想要的实际上是那个最优的压缩方式, 既极小充分统计量

> [!def] 极小充分统计量
> 设 $T$ 是分布族 $\mathcal F$ 的充分统计量, 若对任一充分统计量 $S(X)$, 存在一个函数 $q_{s}(\cdot)$, 使得 $T=q_{s}\circ S$, 则称 $T(X)$ 为此分布的极小充分统计量

那么问题就变成了这种东西的存在性和唯一性, 存在性由 Zorn 引理保证, 唯一性参考下面的讨论

更进一步考虑上述的信息压缩, 我们压缩的实际上是 $X$ 所在的概率空间, 利用似然函数可以进一步说明

> [!thm]
> 对于 $\mathcal P=\{p_{\theta}\}$ 的充分统计量 $T(X)$, 若
> $$L(\theta;x)\propto_{\theta}L(\theta;y)\implies T(x)=T(y)$$
> 则 $T$ 为极小充分统计量

`BEGINPROOF`
反设对于充分统计量 $S$, 不存在 $f$ 使得 $f(S(x))=T(x)$, 则存在 $x,y$ 满足 $S(x)=S(y)$ 但 $T(x)\neq T(y)$, 则
$$L(\theta;x)=g_{\theta}(S(x))h(x)\propto_{\theta} g_{\theta}(S(y))h(y)=L(\theta;y)$$
出现矛盾
`ENDPROOF`
这就是说, 关键看变量的那部分影响了 $L$ 的形状或者 $l$ 的高低

> [!example] Laplace location family
> $$\begin{align}
> p_{\theta}(x)&= \frac{1}{2^n}e^{-|x-\theta|}\\
> p_{\theta}(x)&= \frac{1}{2^n}\exp\left( -\sum|x_{i}-\theta| \right) \\
> l(\theta;x)&=-\sum|x_{i}-\theta|-n\log_{2}
> \end{align}$$
> 其极小充分统计量是 $S(X)=(X_{(1)},\cdots,X_{(n)})$.

^ac3ca2
## 完全统计量

> [!def] 完全统计量
> 设 $\mathcal F$ 为一分布族, $\Theta$ 是其参数空间, 设 $T=T(X)$ 为一统计量, 若对任一满足条件
> $$\mathbb E_{\theta}(\varphi(T(X))),\quad \forall\theta\in\Theta $$
> 的 $\varphi$ 都有
> $$\mathbb P_{\theta}(\varphi(T(X))=0)=1\quad \forall\theta\in\Theta $$
> 则称 $T(X)$ 为一完全统计量

显然完全统计量的任一 (可测) 函数也是完全统计量

(a) 完全统计量可以被理解为极小性的某种加强 (\*), 并不是每个参数族都有完全统计量, 例如在 [[#^ac3ca2]] 中, 对极小充分统计量 $S(X)$ 取
$$f(S(X))=\underbrace{\operatorname{med}(X)}_{中位数}-\bar{X}\implies\mathbb E(f(S(X)))=0, \operatorname{med}(X)\neq_{\text{a.e.}} \bar{X}$$
(b) 实际上他的定义更像满秩, 假定 $T\sim t$, 则定义式可改写为
$$\mathbb E_{\theta}(\varphi(T(X)))=\int \varphi(x)t(x)\ \mathrm{d}\mu(x)=0\implies \varphi(x)\xlongequal{\text{a.e.}}0$$

> [!thm]
> 充分完全统计量一定是极小充分统计量

`BEGINPROOF`
假定存在极小充分统计量 $S(X)$, 充分完全统计量 $T(X)$, 取函数 $m$
$$m(S(X))=\mathbb E_{\theta}[T(X)\mid S(X)]$$
则由于 $S$ 的充分性, $m(S(X))$ 与 $\theta$ 无关. 取 $g(t)=t-m(f(t))$ 则
$$\mathbb E_{\theta}[g(T)]=\mathbb E_{\theta}[T]-\mathbb E_{\theta}[\mathbb E_{\theta}[T\mid S]]=0\qquad \forall\theta$$
由完备性 $T\xlongequal{\text{a.s.}}\mathbb E_{\theta}[T\mid S]\implies T\xlongequal{\text{a.s.}}S$
`ENDPROOF`

> [!example] 指数族中的统计量 $T$
> 对指数族
> $$p_{\theta}(x)=C(\theta)e^{\eta(\theta)^TT(x)}h(x)$$
> 考虑统计量 $T$ 的充分性与完全性, 由于似然函数
> $$\begin{align}
> L(\theta;x)\propto_{\theta}L(\theta;y)&\iff e^{\eta(\theta)^TT(x)}\propto_{\theta}e^{\eta(\theta)T(y)} \\
> &\iff \eta(\theta)^T(T(x)-T(y))=C(x,y)
> \end{align}$$
> 取 $\theta_{1}$, $\theta_{2}$ 对应式子相减得
> $$(\eta(\theta_{1})-\eta(\theta_{2}))^T(T(x)-T(y))=0$$
> 这就是说, 假如我们有 $\operatorname{span}\{\eta(\theta_{1})-\eta(\theta_{2})\}=\mathbb R^k$ 那么 $T$ 为极小充分统计量
> 事实上我们有
> - 当 $\eta(\Theta)$ 有内点时, $T$ 为充分完全统计量 ( #todo )
> - 当 $\operatorname{span}\{\eta(\theta_{1})-\eta(\theta_{2})\}=\mathbb R^k$ 时, $T$ 是极小充分统计量但未必是充分完全统计量
> - 当上述两个条件都不满足时, $T$ 未必是极小充分统计量

## 辅助统计量

> [!def] 辅助统计量
> 对于分布族 $\mathcal F=\{f_{\theta}:\theta\in \Theta\}$ 若统计量 $S$ 的分布与 $\theta$ 无关, 则称 $S$ 为辅助统计量

> [!thm] Basu
> 若 $T$ 为充分完全统计量, $V$ 为辅助统计量, 则对任意 $\theta\in \Theta$, $V(X)$ 与 $T(X)$ 独立

`BEGINPROOF`
试图证明 $\forall A,B,\theta$
$$\mathbb P_{\theta}(V\in A,T\in B)=\mathbb P_{\theta}(V\in A)\mathbb P(T\in B)$$
这等价于
$$\mathbb P_{\theta}(V\in A\mid T\in B)=\mathbb P_{\theta}(V\in A)$$
当 $\mathbb P_{\theta}(T\in B)>0$ 时, 取
$$q_{A}(T(X))=\mathbb P(V\in A\mid T(X)),\qquad p_{A}=\mathbb P(V\in A)$$
由于 $p_{A}$, $q_{A}$ 与 $\theta$ 无关
$$\mathbb E_{\theta}[q_{A}(T(X))-p_{A}]=0$$
从而由完备性立得
`ENDPROOF`

Basu 定理可以用于分辨统计量的独立性, 有时我们也会对一个模型的子模型使用这一定理

> [!exercise]
> $X_{1},\cdots,X_{n}\stackrel{\text{i.i.d}}{\sim}N(\mu,\sigma^2)$, 往证 $\bar{X}$ 与 $S^2$ 独立

`BEGINPROOF`
对任意 $\sigma^2$ 考虑模型
$$\mathcal Q_{\sigma^2}=\{N(\mu,\sigma^2)^n:\mu\in\mathbb R\}$$
写成指数族
$$\begin{align}
f_{\mu}(x)&=(2\pi \sigma^2)^{-n/2}\exp\left\{-\frac{1}{2\sigma^2}\sum(x_{i}-\mu)^2\right\} \\
&=\exp\left\{ -2\mu \sum x_{i}\right\}\frac{n\mu^2}{(2\pi \sigma^2)^{n/2}}e^{\sum x_{i}^2}
\end{align}$$
而 $\mu\in\mathbb R$ 自然参数空间有内点, 这说明 $\bar{X}$ 为 $\mathcal Q_{\sigma^2}$ 的一充分完全统计量 (注意不是原空间), 令一方面, 令 $Z_{i}=X_{i}-\mu\stackrel{\text{i.i.d}}\sim N(0,\sigma^2)$ (事实上这里 $Z$ 不是统计量, 它和 $\mu$ 有关), 则
$$S^2=\frac{1}{n-1}\sum_{i=1}^n(X_{i}-\bar{X})^2=\frac{1}{n-1}\sum(Z_{i}-\bar{Z})$$
的分布与 $\theta$ 无关, 由 Basu 定理, 对任意 $\mu,\sigma^2$ $\bar{X}$ 和 $S^2$ 相互独立
`ENDPROOF`
